{
 "metadata": {
  "name": "",
  "signature": "sha256:6392652e9db37c4689b4c17822790dc561458984aba51ce295d2d0a6195d88aa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#IOOS System Test: [Extreme Events Theme](https://github.com/ioos/system-test/wiki/Development-of-Test-Themes#wiki-theme-2-extreme-events):  Inundation\n",
      "\n",
      "###Compare modeled water levels with observations for a specified bounding box and time period using IOOS recommended service standards for catalog search (CSW) and data retrieval (OPeNDAP & SOS). <p>\n",
      "\n",
      "* Query CSW to find datasets that match criteria\n",
      "* Extract OPeNDAP data endpoints from model datasets and SOS endpoints from observational datasets\n",
      "* OPeNDAP model datasets will be granules\n",
      "* SOS endpoints may be datasets (from ncSOS) or collections of datasets (from NDBC, CO-OPS SOS servers)\n",
      "* Filter SOS services to obtain datasets\n",
      "* Extract data from SOS datasets\n",
      "* Extract data from model datasets at locations of observations\n",
      "* Compare time series data on same vertical datum\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylab import *\n",
      "from owslib.csw import CatalogueServiceWeb\n",
      "from owslib import fes\n",
      "import random\n",
      "import netCDF4\n",
      "import pandas as pd\n",
      "import datetime as dt\n",
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "import cStringIO\n",
      "import iris\n",
      "import urllib2\n",
      "import parser\n",
      "from lxml import etree\n",
      "import cartopy.crs as ccrs\n",
      "import cartopy.feature as cfeature\n",
      "from cartopy.io.img_tiles import MapQuestOpenAerial, MapQuestOSM, OSM"
     ],
     "language": "python",
     "metadata": {
      "input_collapsed": false
     },
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Specify a time range and bounding box of interest:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# specific specific times (UTC) ...\n",
      "\n",
      "# hurricane sandy\n",
      "jd_start = dt.datetime(2012,10,26)\n",
      "jd_stop = dt.datetime(2012,11,2)\n",
      "\n",
      "# 2014 feb 10-15 storm\n",
      "jd_start = dt.datetime(2014,2,10)\n",
      "jd_stop = dt.datetime(2014,2,15)\n",
      "\n",
      "# 2014 recent\n",
      "jd_start = dt.datetime(2014,3,8)\n",
      "jd_stop = dt.datetime(2014,3,11)\n",
      "\n",
      "# 2011 \n",
      "#jd_start = dt.datetime(2013,4,20)\n",
      "#jd_stop = dt.datetime(2013,4,24)\n",
      "\n",
      "# ... or relative to now\n",
      "jd_now = dt.datetime.utcnow()\n",
      "jd_start = jd_now - dt.timedelta(days=3)\n",
      "jd_stop = jd_now + dt.timedelta(days=3)\n",
      "\n",
      "start_date = jd_start.strftime('%Y-%m-%d %H:00')\n",
      "stop_date  = jd_stop.strftime('%Y-%m-%d %H:00')\n",
      "\n",
      "jd_start = dt.datetime.strptime(start_date,'%Y-%m-%d %H:%M')\n",
      "jd_stop = dt.datetime.strptime(stop_date,'%Y-%m-%d %H:%M')\n",
      "\n",
      "print start_date,'to',stop_date\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2015-10-02 13:00 to 2015-10-08 13:00\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bounding Box [lon_min, lat_min, lon_max, lat_max]\n",
      "box=[-75., 39., -71., 41.5]  # new york harbor region\n",
      "#box=[-72.0, 41.0, -69.0, 43.0]   # gulf of maine\n",
      "#box=[-160.0, 18.0, -154., 23.0] #hawaii"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to specify all the names we know for water level, names that will get used in the CSW search, and also to find data in the datasets that are returned.  This is ugly and fragile.  There hopefully will be a better way in the future..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name_list=['water_surface_height_above_reference_datum',\n",
      "    'sea_surface_height_above_geoid','sea_surface_elevation',\n",
      "    'sea_surface_height_above_reference_ellipsoid','sea_surface_height_above_sea_level',\n",
      "    'sea_surface_height','water level']\n",
      "\n",
      "sos_name = 'water_surface_height_above_reference_datum'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Search CSW for datasets of interest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from IPython.core.display import HTML\n",
      "#HTML('<iframe src=http://www.ngdc.noaa.gov/geoportal/ width=950 height=400></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect to CSW, explore it's properties\n",
      "\n",
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw' # NGDC Geoportal\n",
      "#endpoint = 'http://geoport.whoi.edu/geoportal/csw'  # USGS WHSC Geoportal\n",
      "\n",
      "#endpoint = 'http://www.nodc.noaa.gov/geoportal/csw'   # NODC Geoportal: granule level\n",
      "#endpoint = 'http://data.nodc.noaa.gov/geoportal/csw'  # NODC Geoportal: collection level   \n",
      "#endpoint = 'http://geodiscover.cgdi.ca/wes/serviceManagerCSW/csw'  # NRCAN CUSTOM\n",
      "#endpoint = 'http://geoport.whoi.edu/gi-cat/services/cswiso' # USGS Woods Hole GI_CAT\n",
      "#endpoint = 'http://cida.usgs.gov/gdp/geonetwork/srv/en/csw' # USGS CIDA Geonetwork\n",
      "#endpoint = 'http://cmgds.marine.usgs.gov/geonetwork/srv/en/csw' # USGS Coastal and Marine Program\n",
      "#endpoint = 'http://geoport.whoi.edu/geoportal/csw' # USGS Woods Hole Geoportal \n",
      "#endpoint = 'http://geo.gov.ckan.org/csw'  # CKAN testing site for new Data.gov\n",
      "#endpoint = 'https://edg.epa.gov/metadata/csw'  # EPA\n",
      "#endpoint = 'http://cwic.csiss.gmu.edu/cwicv1/discovery'  # CWIC\n",
      "\n",
      "csw = CatalogueServiceWeb(endpoint,timeout=60)\n",
      "csw.version"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "'2.0.2'"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csw.get_operation_by_name('GetRecords').constraints"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[Constraint: SupportedCommonQueryables - ['Subject', 'Title', 'Abstract', 'AnyText', 'Format', 'Identifier', 'Modified', 'Type', 'BoundingBox'],\n",
        " Constraint: SupportedISOQueryables - ['apiso:Subject', 'apiso:Title', 'apiso:Abstract', 'apiso:AnyText', 'apiso:Format', 'apiso:Identifier', 'apiso:Modified', 'apiso:Type', 'apiso:BoundingBox', 'apiso:CRS.Authority', 'apiso:CRS.ID', 'apiso:CRS.Version', 'apiso:RevisionDate', 'apiso:AlternateTitle', 'apiso:CreationDate', 'apiso:PublicationDate', 'apiso:OrganizationName', 'apiso:HasSecurityConstraints', 'apiso:Language', 'apiso:ResourceIdentifier', 'apiso:ParentIdentifier', 'apiso:KeywordType', 'apiso:TopicCategory', 'apiso:ResourceLanguage', 'apiso:GeographicDescriptionCode', 'apiso:Denominator', 'apiso:DistanceValue', 'apiso:DistanceUOM', 'apiso:TempExtent_begin', 'apiso:TempExtent_end', 'apiso:ServiceType', 'apiso:ServiceTypeVersion', 'apiso:Operation', 'apiso:OperatesOn', 'apiso:OperatesOnIdentifier', 'apiso:OperatesOnName', 'apiso:CouplingType'],\n",
        " Constraint: AdditionalQueryables - ['apiso:Degree', 'apiso:AccessConstraints', 'apiso:OtherConstraints', 'apiso:Classification', 'apiso:ConditionApplyingToAccessAndUse', 'apiso:Lineage', 'apiso:ResponsiblePartyRole', 'apiso:ResponsiblePartyName', 'apiso:SpecificationTitle', 'apiso:SpecificationDate', 'apiso:SpecificationDateType']]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# hopefully something like this will be implemented in fes soon\n",
      "def dateRange(start_date='1900-01-01',stop_date='2100-01-01',constraint='overlaps'):\n",
      "    if constraint == 'overlaps':\n",
      "        start = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=stop_date)\n",
      "        stop = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=start_date)\n",
      "    elif constraint == 'within':\n",
      "        start = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=start_date)\n",
      "        stop = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=stop_date)\n",
      "    return start,stop"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stop_date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "'2015-10-08 13:00'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert User Input into FES filters\n",
      "start,stop = dateRange(start_date,stop_date)\n",
      "bbox = fes.BBox(box)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "or_filt = fes.Or([fes.PropertyIsLike(propertyname='apiso:AnyText',literal=('*%s*' % val),\n",
      "                    escapeChar='\\\\',wildCard='*',singleChar='?') for val in name_list])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ROMS model output often has Averages and History files.  The Averages files are usually averaged over a tidal cycle or more, while the History files are snapshots at that time instant.  We are not interested in averaged data for this test, so in the cell below we remove any Averages files here by removing any datasets that have the term \"Averages\" in the metadata text.  A better approach would be to look at the `cell_methods` attributes propagated through to some term in the ISO metadata, but this is not implemented yet, as far as I know"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val = 'Averages'\n",
      "not_filt = fes.Not([fes.PropertyIsLike(propertyname='apiso:AnyText',literal=('*%s*' % val),\n",
      "                        escapeChar='\\\\',wildCard='*',singleChar='?')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter_list = [fes.And([ bbox, start, stop, or_filt, not_filt]) ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# try request using multiple filters \"and\" syntax: [[filter1,filter2]]\n",
      "csw.getrecords2(constraints=filter_list,maxrecords=1000,esn='full')\n",
      "print len(csw.records.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now print out some titles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for rec,item in csw.records.iteritems():\n",
      "    print item.title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NYHOPS Forecast Model Results\n",
        "ROMS ESPRESSO Real-Time Operational IS4DVAR Forecast System Version 2 (NEW) 2013-present FMRC History\n",
        "NECOFS GOM3 (FVCOM) - Northeast US - Latest Forecast\n",
        "NECOFS GOM3 Wave - Northeast US - Latest Forecast\n",
        "DBOFS - Delaware Bay Operational Forecast System - NOAA CO-OPS - POM\n",
        "NYOFS - New York and New Jersey Operational Forecast System - NOAA CO-OPS - POM\n",
        "Barotropic Tide Model for the Pacific Basin\n",
        "CBOFS - Chesapeake Bay Operational Forecast System - NOAA CO-OPS - POM\n",
        "ESTOFS Storm Surge Model - Atlantic - v1.0.0 - NOAA - NCEP - ADCIRC\n",
        "NECOFS Massachusetts (FVCOM) - Massachusetts Coastal - Latest Forecast\n",
        "NDBC Standard Meteorological Buoy Data\n",
        "HYbrid Coordinate Ocean Model (HYCOM): Global\n",
        "HRECOS Aggregated Station HRPIER84 Data\n",
        "HRECOS Aggregated Station HRPMNTH Data\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define a function that will return the endpoint for a specified service type"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def service_urls(records,service_string='urn:x-esri:specification:ServiceType:odp:url'):\n",
      "    \"\"\"\n",
      "    extract service_urls of a specific type (DAP, SOS) from records\n",
      "    \"\"\"\n",
      "    urls=[]\n",
      "    for key,rec in records.iteritems():\n",
      "        #create a generator object, and iterate through it until the match is found\n",
      "        #if not found, gets the default value (here \"none\")\n",
      "        url = next((d['url'] for d in rec.references if d['scheme'] == service_string), None)\n",
      "        if url is not None:\n",
      "            urls.append(url)\n",
      "    return urls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Print out all the OPeNDAP Data URL endpoints"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dap_urls = service_urls(csw.records,service_string='urn:x-esri:specification:ServiceType:odp:url')\n",
      "print \"\\n\".join(dap_urls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://colossus.dl.stevens-tech.edu:8080/thredds/dodsC/latest/Complete_gcmplt.nc\n",
        "http://tds.marine.rutgers.edu/thredds/dodsC/roms/espresso/2013_da/his/ESPRESSO_Real-Time_v2_History_Best\n",
        "http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
        "http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_WAVE_FORECAST.nc\n",
        "http://opendap.co-ops.nos.noaa.gov/thredds/dodsC/DBOFS/fmrc/Aggregated_7_day_DBOFS_Fields_Forecast_best.ncd\n",
        "http://opendap.co-ops.nos.noaa.gov/thredds/dodsC/NYOFS/fmrc/Aggregated_7_day_NYOFS_Fields_Forecast_best.ncd\n",
        "http://oos.soest.hawaii.edu/thredds/dodsC/hioos/tide_pac\n",
        "http://opendap.co-ops.nos.noaa.gov/thredds/dodsC/CBOFS/fmrc/Aggregated_7_day_CBOFS_Fields_Forecast_best.ncd\n",
        "http://geoport-dev.whoi.edu/thredds/dodsC/estofs/atlantic\n",
        "http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_FVCOM_OCEAN_MASSBAY_FORECAST.nc\n",
        "http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global\n",
        "http://sos.maracoos.org/stable/dodsC/hrecos/stationHRPIER84-agg.ncml\n",
        "http://sos.maracoos.org/stable/dodsC/hrecos/stationHRPMNTH-agg.ncml\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Print out all the SOS Data URL endpoints"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sos_urls = service_urls(csw.records,service_string='urn:x-esri:specification:ServiceType:sos:url')\n",
      "print \"\\n\".join(sos_urls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://sos.maracoos.org/stable/sos/hrecos/stationHRPIER84-agg.ncml?service=SOS&version=1.0.0&request=GetCapabilities\n",
        "http://sos.maracoos.org/stable/sos/hrecos/stationHRPMNTH-agg.ncml?service=SOS&version=1.0.0&request=GetCapabilities\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nearxy(x,y,xi,yi):\n",
      "    \"\"\"\n",
      "    find the indices x[i] of arrays (x,y) closest to the points (xi,yi)\n",
      "    \"\"\"\n",
      "    ind=ones(len(xi),dtype=int)\n",
      "    dd=ones(len(xi),dtype='float')\n",
      "    for i in arange(len(xi)):\n",
      "        dist=sqrt((x-xi[i])**2+(y-yi[i])**2)\n",
      "        ind[i]=dist.argmin()\n",
      "        dd[i]=dist[ind[i]]\n",
      "    return ind,dd"
     ],
     "language": "python",
     "metadata": {
      "input_collapsed": true
     },
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_ij(x,y,d,xi,yi):\n",
      "    \"\"\"\n",
      "    find non-NaN cell d[j,i] that are closest to points (xi,yi).\n",
      "    \"\"\"\n",
      "    index = where(~isnan(d.flatten()))[0]\n",
      "    ind,dd = nearxy(x.flatten()[index],y.flatten()[index],xi,yi)\n",
      "    j,i=ind2ij(x,index[ind])\n",
      "    return i,j,dd\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def find_timevar(cube):\n",
      "    \"\"\"\n",
      "    return the time variable from Iris. This is a workaround for\n",
      "    Iris having problems with FMRC aggregations, which produce two time coordinates\n",
      "    \"\"\"\n",
      "    try:\n",
      "        cube.coord(axis='T').rename('time')\n",
      "    except:\n",
      "        pass\n",
      "    timevar = cube.coord('time')\n",
      "    return timevar\n",
      "    "
     ],
     "language": "python",
     "metadata": {
      "input_collapsed": true
     },
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ind2ij(a,index):\n",
      "    \"\"\"\n",
      "    returns a[j,i] for a.ravel()[index]\n",
      "    \"\"\"\n",
      "    n,m = shape(lon)\n",
      "    j = ceil(index/m).astype(int)\n",
      "    i = remainder(index,m)\n",
      "    return i,j"
     ],
     "language": "python",
     "metadata": {
      "input_collapsed": true
     },
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Get observations from SOS\n",
      "Here we are using a custom class from pyoos to read the CO-OPS SOS.  This is definitely unsavory, as the whole point of using a standard is avoid the need for custom classes for each service.  Need to examine the consequences of removing this and just going with straight SOS service using OWSLib. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collector = CoopsSos()\n",
      "collector.set_datum('NAVD')\n",
      "#collector.set_datum('MSL')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collector.server.identification.title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "'NOAA.NOS.CO-OPS SOS'"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collector.start_time = jd_start\n",
      "collector.end_time = jd_stop\n",
      "collector.variables = [sos_name]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ofrs = collector.server.offerings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(ofrs)\n",
      "for p in ofrs[700:710]: print p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1052\n",
        "Offering id: station-UNI1019, name: urn:ioos:station:NOAA.NOS.CO-OPS:UNI1019\n",
        "Offering id: station-UNI1020, name: urn:ioos:station:NOAA.NOS.CO-OPS:UNI1020\n",
        "Offering id: station-UNI1021, name: urn:ioos:station:NOAA.NOS.CO-OPS:UNI1021\n",
        "Offering id: station-UNI1022, name: urn:ioos:station:NOAA.NOS.CO-OPS:UNI1022\n",
        "Offering id: station-UNI1023, name: urn:ioos:station:NOAA.NOS.CO-OPS:UNI1023\n",
        "Offering id: station-UNI1024, name: urn:ioos:station:NOAA.NOS.CO-OPS:UNI1024\n",
        "Offering id: station-WAC1401, name: urn:ioos:station:NOAA.NOS.CO-OPS:WAC1401\n",
        "Offering id: station-1611400, name: urn:ioos:station:NOAA.NOS.CO-OPS:1611400\n",
        "Offering id: station-1612340, name: urn:ioos:station:NOAA.NOS.CO-OPS:1612340\n",
        "Offering id: station-1612480, name: urn:ioos:station:NOAA.NOS.CO-OPS:1612480\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Find the SOS stations within our bounding box and time extent\n",
      "We would like to just use a filter on a collection to get a new collection, but PYOOS doesn't do that yet. So we do a GetObservation request for a collection, including a bounding box, and asking for one value at the start of the time period of interest.   We use that to do a bounding box filter on the SOS server, which returns 1 point for each station found.  So for 3 stations, we get back 3 records, in CSV format.  We can strip the station ids from the CSV, and then we have a list of stations we can use with pyoos.  The template for the GetObservation query for the bounding box filtered collection was generated using the GUI at http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iso_start = jd_start.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "print iso_start\n",
      "box_str=','.join(str(e) for e in box)\n",
      "print box_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2015-10-02T13:00:00Z\n",
        "-75.0,39.0,-71.0,41.5\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url=('http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?'\n",
      "     'service=SOS&request=GetObservation&version=1.0.0&'\n",
      "     'observedProperty=%s&offering=urn:ioos:network:NOAA.NOS.CO-OPS:WaterLevelActive&'\n",
      "     'featureOfInterest=BBOX:%s&responseFormat=text/csv&eventTime=%s') % (sos_name,box_str,iso_start)\n",
      "print url\n",
      "obs_loc_df = pd.read_csv(url)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?service=SOS&request=GetObservation&version=1.0.0&observedProperty=water_surface_height_above_reference_datum&offering=urn:ioos:network:NOAA.NOS.CO-OPS:WaterLevelActive&featureOfInterest=BBOX:-75.0,39.0,-71.0,41.5&responseFormat=text/csv&eventTime=2015-10-02T13:00:00Z\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_loc_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>station_id</th>\n",
        "      <th>sensor_id</th>\n",
        "      <th>latitude (degree)</th>\n",
        "      <th>longitude (degree)</th>\n",
        "      <th>date_time</th>\n",
        "      <th>water_surface_height_above_reference_datum (m)</th>\n",
        "      <th>datum_id</th>\n",
        "      <th>vertical_position (m)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>urn:ioos:station:NOAA.NOS.CO-OPS:8461490</td>\n",
        "      <td>urn:ioos:sensor:NOAA.NOS.CO-OPS:8461490:A1</td>\n",
        "      <td>41.3614</td>\n",
        "      <td>-72.0900</td>\n",
        "      <td>2015-10-02T13:00:00Z</td>\n",
        "      <td>0.489</td>\n",
        "      <td>urn:ioos:def:datum:noaa::MLLW</td>\n",
        "      <td>1.074</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>urn:ioos:station:NOAA.NOS.CO-OPS:8465705</td>\n",
        "      <td>urn:ioos:sensor:NOAA.NOS.CO-OPS:8465705:A1</td>\n",
        "      <td>41.2833</td>\n",
        "      <td>-72.9083</td>\n",
        "      <td>2015-10-02T13:00:00Z</td>\n",
        "      <td>0.307</td>\n",
        "      <td>urn:ioos:def:datum:noaa::MLLW</td>\n",
        "      <td>5.618</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>urn:ioos:station:NOAA.NOS.CO-OPS:8510560</td>\n",
        "      <td>urn:ioos:sensor:NOAA.NOS.CO-OPS:8510560:A1</td>\n",
        "      <td>41.0483</td>\n",
        "      <td>-71.9600</td>\n",
        "      <td>2015-10-02T13:00:00Z</td>\n",
        "      <td>0.592</td>\n",
        "      <td>urn:ioos:def:datum:noaa::MLLW</td>\n",
        "      <td>1.177</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>urn:ioos:station:NOAA.NOS.CO-OPS:8516945</td>\n",
        "      <td>urn:ioos:sensor:NOAA.NOS.CO-OPS:8516945:A1</td>\n",
        "      <td>40.8103</td>\n",
        "      <td>-73.7649</td>\n",
        "      <td>2015-10-02T13:00:00Z</td>\n",
        "      <td>0.593</td>\n",
        "      <td>urn:ioos:def:datum:noaa::MLLW</td>\n",
        "      <td>3.928</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>urn:ioos:station:NOAA.NOS.CO-OPS:8518750</td>\n",
        "      <td>urn:ioos:sensor:NOAA.NOS.CO-OPS:8518750:A1</td>\n",
        "      <td>40.7006</td>\n",
        "      <td>-74.0142</td>\n",
        "      <td>2015-10-02T13:00:00Z</td>\n",
        "      <td>1.279</td>\n",
        "      <td>urn:ioos:def:datum:noaa::MLLW</td>\n",
        "      <td>1.002</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "                                 station_id  \\\n",
        "0  urn:ioos:station:NOAA.NOS.CO-OPS:8461490   \n",
        "1  urn:ioos:station:NOAA.NOS.CO-OPS:8465705   \n",
        "2  urn:ioos:station:NOAA.NOS.CO-OPS:8510560   \n",
        "3  urn:ioos:station:NOAA.NOS.CO-OPS:8516945   \n",
        "4  urn:ioos:station:NOAA.NOS.CO-OPS:8518750   \n",
        "\n",
        "                                    sensor_id  latitude (degree)  \\\n",
        "0  urn:ioos:sensor:NOAA.NOS.CO-OPS:8461490:A1            41.3614   \n",
        "1  urn:ioos:sensor:NOAA.NOS.CO-OPS:8465705:A1            41.2833   \n",
        "2  urn:ioos:sensor:NOAA.NOS.CO-OPS:8510560:A1            41.0483   \n",
        "3  urn:ioos:sensor:NOAA.NOS.CO-OPS:8516945:A1            40.8103   \n",
        "4  urn:ioos:sensor:NOAA.NOS.CO-OPS:8518750:A1            40.7006   \n",
        "\n",
        "   longitude (degree)             date_time  \\\n",
        "0            -72.0900  2015-10-02T13:00:00Z   \n",
        "1            -72.9083  2015-10-02T13:00:00Z   \n",
        "2            -71.9600  2015-10-02T13:00:00Z   \n",
        "3            -73.7649  2015-10-02T13:00:00Z   \n",
        "4            -74.0142  2015-10-02T13:00:00Z   \n",
        "\n",
        "   water_surface_height_above_reference_datum (m)  \\\n",
        "0                                           0.489   \n",
        "1                                           0.307   \n",
        "2                                           0.592   \n",
        "3                                           0.593   \n",
        "4                                           1.279   \n",
        "\n",
        "                        datum_id  vertical_position (m)  \n",
        "0  urn:ioos:def:datum:noaa::MLLW                  1.074  \n",
        "1  urn:ioos:def:datum:noaa::MLLW                  5.618  \n",
        "2  urn:ioos:def:datum:noaa::MLLW                  1.177  \n",
        "3  urn:ioos:def:datum:noaa::MLLW                  3.928  \n",
        "4  urn:ioos:def:datum:noaa::MLLW                  1.002  "
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stations = [sta.split(':')[-1] for sta in obs_loc_df['station_id']]\n",
      "print stations\n",
      "obs_lon = [sta for sta in obs_loc_df['longitude (degree)']]\n",
      "obs_lat = [sta for sta in obs_loc_df['latitude (degree)']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['8461490', '8465705', '8510560', '8516945', '8518750', '8519483', '8531680', '8534720', '8539094', '8548989']\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get longName from SOS DescribeSensor (station) request"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_Coops_longName(sta):\n",
      "    \"\"\"\n",
      "    get longName for specific station from COOPS SOS using DescribeSensor request\n",
      "    \"\"\"\n",
      "    url=('http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?service=SOS&'\n",
      "        'request=DescribeSensor&version=1.0.0&outputFormat=text/xml;subtype=\"sensorML/1.0.1\"&'\n",
      "        'procedure=urn:ioos:station:NOAA.NOS.CO-OPS:%s') % sta\n",
      "    tree = etree.parse(urllib2.urlopen(url))\n",
      "    root = tree.getroot()\n",
      "    longName=root.xpath(\"//sml:identifier[@name='longName']/sml:Term/sml:value/text()\", namespaces={'sml':\"http://www.opengis.net/sensorML/1.0.1\"})\n",
      "    return longName"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Request CSV response from SOS and convert to Pandas DataFrames"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def coops2df(collector,coops_id,sos_name):\n",
      "    collector.features = [coops_id]\n",
      "    collector.variables = [sos_name]\n",
      "    try:\n",
      "        response = collector.raw(responseFormat=\"text/csv\")\n",
      "\n",
      "        data_df = pd.read_csv(cStringIO.StringIO(str(response)), parse_dates=True, index_col='date_time')\n",
      "\n",
      "#    data_df['Observed Data']=data_df['water_surface_height_above_reference_datum (m)']-data_df['vertical_position (m)']\n",
      "        data_df['Observed Data']=data_df['water_surface_height_above_reference_datum (m)']\n",
      "\n",
      "        a = get_Coops_longName(coops_id)\n",
      "        if len(a)==0:\n",
      "            long_name=coops_id\n",
      "        else:\n",
      "            long_name=a[0]\n",
      "\n",
      "        data_df.name=long_name\n",
      "    except:\n",
      "        print('datum not found')\n",
      "    return data_df"
     ],
     "language": "python",
     "metadata": {
      "input_collapsed": true
     },
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate a uniform 6-min time base for model/data comparison:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ts_rng = pd.date_range(start=jd_start, end=jd_stop, freq='6Min')\n",
      "ts = pd.DataFrame(index=ts_rng)\n",
      "print jd_start,jd_stop\n",
      "print len(ts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2015-10-02 13:00:00 2015-10-08 13:00:00\n",
        "1441\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a list of obs dataframes, one for each station:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_df=[]\n",
      "sta_names=[]\n",
      "for sta in stations:\n",
      "    b=coops2df(collector,sta,sos_name)\n",
      "    sta_names.append(b.name)\n",
      "    print b.name\n",
      "    # limit interpolation to 10 points (10 @ 6min = 1 hour)\n",
      "    obs_df.append(pd.DataFrame(pd.concat([b, ts],axis=1).interpolate(limit=10)['Observed Data']))\n",
      "    obs_df[-1].name=b.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "New London, CT\n"
       ]
      },
      {
       "ename": "ExceptionReport",
       "evalue": "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mExceptionReport\u001b[0m                           Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-39-ac241e0de238>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msta_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msta\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoops2df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcollector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msos_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0msta_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-37-e299295225d8>\u001b[0m in \u001b[0;36mcoops2df\u001b[1;34m(collector, coops_id, sos_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcollector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcoops_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcollector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msos_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponseFormat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"text/csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcStringIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'date_time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/usgs/miniconda/envs/ioos/lib/python2.7/site-packages/pyoos-0.6.2-py2.7.egg/pyoos/collectors/ioos/swe_sos.pyc\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_observation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/usgs/miniconda/envs/ioos/lib/python2.7/site-packages/owslib/swe/observation/sos100.pyc\u001b[0m in \u001b[0;36mget_observation\u001b[1;34m(self, responseFormat, offerings, observedProperties, eventTime, procedure, method, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0metree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnspath_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ows:ExceptionReport\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExceptionReport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mExceptionReport\u001b[0m: 'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.transforms import offset_copy\n",
      "geodetic = ccrs.Geodetic(globe=ccrs.Globe(datum='WGS84'))\n",
      "figure(figsize=(8,8))\n",
      "# Open Source Imagery from MapQuest (max zoom = 16?)\n",
      "tiler = MapQuestOpenAerial()\n",
      "# Open Street Map (max zoom = 18?)\n",
      "#tiler = OSM()\n",
      "ax = plt.axes(projection=tiler.crs)\n",
      "extent=[box[0],box[2],box[1],box[3]]\n",
      "ax.set_extent(extent, geodetic)\n",
      "ax.add_image(tiler, 7)\n",
      "plt.scatter(obs_lon,obs_lat,marker='o',s=30.0,\n",
      "         color='cyan',transform=ccrs.PlateCarree())\n",
      "geodetic_transform = ccrs.Geodetic()._as_mpl_transform(ax)\n",
      "text_transform = offset_copy(geodetic_transform, units='dots', x=-7,y=+7)\n",
      "\n",
      "for x,y,label in zip(obs_lon,obs_lat,sta_names):\n",
      "    plt.text(x,y,label,horizontalalignment='left',transform=text_transform,color='white')\n",
      "gl=ax.gridlines(draw_labels=True)\n",
      "gl.xlabels_top = False\n",
      "gl.ylabels_right = False\n",
      "title('Water Level Gauge Locations')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get model output from OPeNDAP URLS\n",
      "Try to open all the OPeNDAP URLS using Iris from the British Met Office.  If 1D, assume dataset is data, if 2D assume dataset is an unstructured grid model, and if 3D, assume it's a structured grid model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Construct an Iris contraint to load only cubes that match the std_name_list:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print name_list\n",
      "def name_in_list(cube):\n",
      "    return cube.standard_name in name_list\n",
      "constraint = iris.Constraint(cube_func=name_in_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mod_df(arr,timevar,istart,istop,mod_name,ts):\n",
      "    \"\"\"\n",
      "    return time series (DataFrame) from model interpolated onto uniform time base\n",
      "    \"\"\"\n",
      "    t=timevar.points[istart:istop]\n",
      "    jd = timevar.units.num2date(t)\n",
      "\n",
      "    # eliminate any data that is closer together than 10 seconds\n",
      "    # this was required to handle issues with CO-OPS aggregations, I think because\n",
      "    # they use floating point time in hours, which is not very accurate, so the FMRC\n",
      "    # aggregation is aggregating points that actually occur at the same time\n",
      "    dt =diff(jd)\n",
      "    s = array([ele.seconds for ele in dt])\n",
      "    ind=where(s>10)[0]\n",
      "    arr=arr[ind+1]\n",
      "    jd=jd[ind+1]\n",
      "    \n",
      "    b = pd.DataFrame(arr,index=jd,columns=[mod_name])\n",
      "    # eliminate any data with NaN\n",
      "    b = b[isfinite(b[mod_name])]\n",
      "    # interpolate onto uniform time base, fill gaps up to: (10 values @ 6 min = 1 hour)\n",
      "    c = pd.concat([b, ts],axis=1).interpolate(limit=10)\n",
      "    return c\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use only data within 0.04 degrees (about 4 km)\n",
      "max_dist=0.04 \n",
      "\n",
      "# use only data where the standard deviation of the time series exceeds 0.01 m (1 cm)\n",
      "# this eliminates flat line model time series that come from land points that \n",
      "# should have had missing values.\n",
      "min_var=0.01\n",
      "\n",
      "for url in dap_urls:\n",
      "    try:\n",
      "        a = iris.load_cube(url,constraint)\n",
      "        # convert to units of meters\n",
      " #       a.convert_units('m')     # this isn't working for unstructured data\n",
      "        # take first 20 chars for model name\n",
      "        mod_name = a.attributes['title'][0:20]\n",
      "        r = shape(a)\n",
      "        timevar = find_timevar(a)\n",
      "        lat = a.coord(axis='Y').points\n",
      "        lon = a.coord(axis='X').points\n",
      "        jd = timevar.units.num2date(timevar.points)\n",
      "        istart = timevar.nearest_neighbour_index(timevar.units.date2num(jd_start))\n",
      "        istop = timevar.nearest_neighbour_index(timevar.units.date2num(jd_stop))\n",
      "        \n",
      "        # only proceed if we have data in the range requested\n",
      "        if istart != istop:            \n",
      "            nsta = len(obs_lon)\n",
      "            if len(r)==3:\n",
      "                print '[Structured grid model]:', url\n",
      "                d = a[0,:,:].data\n",
      "                # find the closest non-land point from a structured grid model\n",
      "                if len(shape(lon))==1:\n",
      "                    lon,lat= meshgrid(lon,lat)\n",
      "                j,i,dd = find_ij(lon,lat,d,obs_lon,obs_lat)\n",
      "                for n in range(nsta):\n",
      "                    # only use if model cell is within 0.1 degree of requested location\n",
      "                    if dd[n] <= max_dist:\n",
      "                        arr = a[istart:istop,j[n],i[n]].data                    \n",
      "                        if arr.std() >= min_var:\n",
      "                            c = mod_df(arr,timevar,istart,istop,mod_name,ts)\n",
      "                            name= obs_df[n].name\n",
      "                            obs_df[n]=pd.concat([obs_df[n],c],axis=1)\n",
      "                            obs_df[n].name = name\n",
      "            elif len(r)==2:\n",
      "                print '[Unstructured grid model]:', url\n",
      "                # find the closest point from an unstructured grid model\n",
      "                index,dd = nearxy(lon.flatten(),lat.flatten(),obs_lon,obs_lat)\n",
      "                for n in range(nsta):\n",
      "                    # only use if model cell is within 0.1 degree of requested location\n",
      "                    if dd[n] <= max_dist:\n",
      "                        arr = a[istart:istop,index[n]].data\n",
      "                        if arr.std() >= min_var:\n",
      "                            c = mod_df(arr,timevar,istart,istop,mod_name,ts)\n",
      "                            name = obs_df[n].name\n",
      "                            obs_df[n]=pd.concat([obs_df[n],c],axis=1)\n",
      "                            obs_df[n].name = name \n",
      "            elif len(r)==1:\n",
      "                print '[Data]:', url\n",
      "                        \n",
      "    except:\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for df in obs_df:\n",
      "    print df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for df in obs_df:\n",
      "    p=df.plot(figsize=(14,6),title=df.name,legend=False)\n",
      "    setp(p.lines[0],linewidth=4.0,color=[0.7,0.7,0.7],zorder=1)\n",
      "    legend()\n",
      "    ylabel('m')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# plot again, but now remove the mean offset (relative to data) from all plots\n",
      "for df in obs_df:\n",
      "    amean=df[jd_start:jd_now].mean()\n",
      "    df = df - amean + amean.ix[0]\n",
      "#    print amean.ix[0]-amean\n",
      "    df.plot(figsize=(14,6))\n",
      "    ylabel('m')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_lon"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_lat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}